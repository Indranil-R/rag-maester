{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Indranil-R/rag-maester/blob/master/rag_maester.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f875d2fa-8df2-4951-9bfb-87b71c8b5e1b",
      "metadata": {
        "id": "f875d2fa-8df2-4951-9bfb-87b71c8b5e1b"
      },
      "source": [
        "<!-- ![](assets/img/image.png) -->\n",
        "## RAG Maester\n",
        "**Your AI Scholar**\n",
        "\n",
        "Welcome to **RAG Maester**, an Academic AI assistant designed to support academic excellence.\n",
        "It leverages **Retrieval Augmented Generation (RAG)** to meticulously search its knowledge base and craft well-informed responses, designed to assist with university assignments and tasks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "SbNoeCZ-IEFR",
      "metadata": {
        "id": "SbNoeCZ-IEFR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "QbdP1TauEu-D",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QbdP1TauEu-D",
        "outputId": "c9fb5003-48f7-4714-fe6b-845edf78a487"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirements.txt already exists. Downloading modules...\n"
          ]
        }
      ],
      "source": [
        "# Downloading the required modules\n",
        "if os.path.isfile(\"requirements.txt\"):\n",
        "  print(\"Requirements.txt already exists. Downloading modules...\")\n",
        "else:\n",
        "  print(\"Requirements.txt doesn't exist downloading from github...\")\n",
        "  url = 'https://raw.githubusercontent.com/Indranil-R/rag-maester/refs/heads/master/requirements.txt'\n",
        "  response = requests.get(url)\n",
        "\n",
        "  with open('requirements.txt', 'w', encoding='utf-8') as file:\n",
        "    file.write(response.text)\n",
        "  print(\"File downloaded successfully.\")\n",
        "\n",
        "# !pip install -q -r requirements.txt  # Enable it only if dependencies are not installed, I have installed already"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac42ccfa-7fdf-44ff-9e93-aabc88c74453",
      "metadata": {
        "id": "ac42ccfa-7fdf-44ff-9e93-aabc88c74453"
      },
      "source": [
        "## Importing all required third party libraries\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3e896eba-e5de-45a3-89e2-0de1167d6222",
      "metadata": {
        "id": "3e896eba-e5de-45a3-89e2-0de1167d6222"
      },
      "outputs": [],
      "source": [
        "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
        "    from google.colab import userdata\n",
        "else:\n",
        "    # do nothing\n",
        "    pass\n",
        "\n",
        "\n",
        "from loguru import logger\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d-QNUpRJMLqf",
      "metadata": {
        "id": "d-QNUpRJMLqf"
      },
      "outputs": [],
      "source": [
        "# Setting up Google API key\n",
        "if os.getenv('GOOGLE_API_KEY') == None:\n",
        "  os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d42d5fee-8773-47c9-a070-80aae4524516",
      "metadata": {
        "id": "d42d5fee-8773-47c9-a070-80aae4524516"
      },
      "source": [
        "## 1. Upload and Ingest Documents ðŸ“„"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42271c07-9995-4d18-a2e4-5b2abb3c7088",
      "metadata": {
        "id": "42271c07-9995-4d18-a2e4-5b2abb3c7088"
      },
      "source": [
        "### Scan the docs directory for all available documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "0b0c0b93-1cf3-409f-993c-10b0bf91b43f",
      "metadata": {
        "id": "0b0c0b93-1cf3-409f-993c-10b0bf91b43f",
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Fetch all file paths from a directory\n",
        "\n",
        "def fetch_all_docs(docs_path: str) -> list[str]:\n",
        "    docs_list = []\n",
        "    if not os.path.isdir(docs_path):\n",
        "        print(f\"Warning: The path '{docs_path}' is not a valid directory or does not exist.\")\n",
        "        return []\n",
        "    try:\n",
        "        for item_name in os.listdir(docs_path):\n",
        "            item_full_path = os.path.join(docs_path, item_name)\n",
        "            if os.path.isfile(item_full_path):\n",
        "                docs_list.append(item_full_path)\n",
        "    except OSError as e:\n",
        "        logger.error(f\"Error accessing or reading directory '{docs_path}': {e}\")\n",
        "        return []\n",
        "    return docs_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "962f7cfa-8f7f-4dba-8a1d-36b2b30730bb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "962f7cfa-8f7f-4dba-8a1d-36b2b30730bb",
        "outputId": "26a74205-6468-4989-a113-1e1bbcddf83a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2025-05-17 01:10:38.879\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 0>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1mTotal number of documents found: 3\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Fetching all documents from the docs directory\n",
        "documents_list = fetch_all_docs(os.getcwd() + \"/docs\")\n",
        "\n",
        "logger.info(f\"Total number of documents found: {len(documents_list)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73fc996afb95cabb",
      "metadata": {
        "id": "73fc996afb95cabb"
      },
      "source": [
        "#### Split the documents into smaller chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c4602da5-1e12-461c-ab02-dedd3101f839",
      "metadata": {
        "id": "c4602da5-1e12-461c-ab02-dedd3101f839",
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Clean text by removing predefined phrases\n",
        "\n",
        "def clean_text(text):\n",
        "    removal_phrases = [\n",
        "        \"(c) Amity University Online\",\n",
        "        \"Notes\",\n",
        "        \"Amity Directorate of Distance & Online Education\",\n",
        "        \"Introduction to E-Governance\"\n",
        "    ]\n",
        "    for phrase in removal_phrases:\n",
        "        text = text.replace(phrase, \"\")\n",
        "    return text.strip()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f00ca8da-23c6-4f4f-92a8-0fdb1a25b547",
      "metadata": {
        "id": "f00ca8da-23c6-4f4f-92a8-0fdb1a25b547",
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Load a PDF from the 6th page onward, clean, and split into chunks\n",
        "\n",
        "def load_and_split_pdf(doc_path):\n",
        "    loader = PyPDFLoader(file_path=doc_path, mode=\"page\")\n",
        "    all_pages = loader.load()\n",
        "    relevant_pages = all_pages[5:]\n",
        "    for page in relevant_pages:\n",
        "        page.page_content = clean_text(page.page_content)\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=1500,\n",
        "        chunk_overlap=250,\n",
        "        separators=[\"\\n\\n\", \"\\n\", \".\", \" \"],\n",
        "    )\n",
        "    return text_splitter.split_documents(relevant_pages)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "4ab2708b5edf5152",
      "metadata": {
        "id": "4ab2708b5edf5152",
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Process multiple PDF documents into cleaned, chunked outputs\n",
        "\n",
        "def process_documents(documents_path_list: list[str]) -> list:\n",
        "    all_processed_chunks = []\n",
        "    for doc_path in documents_path_list:\n",
        "        logger.info(f\"Processing document: {doc_path}\")\n",
        "        try:\n",
        "            single_doc_chunks = load_and_split_pdf(doc_path)\n",
        "            if single_doc_chunks:\n",
        "                all_processed_chunks.extend(single_doc_chunks)\n",
        "                logger.info(f\"Successfully processed and extracted {len(single_doc_chunks)} chunks from {doc_path}\")\n",
        "            else:\n",
        "                logger.warning(f\"No relevant chunks found in {doc_path}.\")\n",
        "        except FileNotFoundError:\n",
        "            logger.error(f\"File not found: {doc_path}. Please check the file path.\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error processing document {doc_path}: {e}\")\n",
        "    return all_processed_chunks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "de142ddf38b6c5e3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de142ddf38b6c5e3",
        "outputId": "efa5b5ed-b29c-4a7d-ef84-5e6a51e93816"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2025-05-17 01:10:38.932\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_documents\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mProcessing document: /content/docs/Introduction to Data Science F-CSIT359-S.pdf\u001b[0m\n",
            "\u001b[32m2025-05-17 01:10:50.221\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_documents\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mSuccessfully processed and extracted 961 chunks from /content/docs/Introduction to Data Science F-CSIT359-S.pdf\u001b[0m\n",
            "\u001b[32m2025-05-17 01:10:50.224\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_documents\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mProcessing document: /content/docs/Introduction to E-Governance F-CSIT326 S.pdf\u001b[0m\n",
            "\u001b[32m2025-05-17 01:10:54.708\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_documents\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mSuccessfully processed and extracted 978 chunks from /content/docs/Introduction to E-Governance F-CSIT326 S.pdf\u001b[0m\n",
            "\u001b[32m2025-05-17 01:10:54.712\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_documents\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mProcessing document: /content/docs/Blockchain Technologies F-CSIT358-B.pdf\u001b[0m\n",
            "\u001b[32m2025-05-17 01:10:58.670\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_documents\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mSuccessfully processed and extracted 979 chunks from /content/docs/Blockchain Technologies F-CSIT358-B.pdf\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "documents = process_documents(documents_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea554aef-a1c8-4457-bfff-e71d0c2f21fe",
      "metadata": {
        "id": "ea554aef-a1c8-4457-bfff-e71d0c2f21fe"
      },
      "source": [
        "# 2. Create Embeddings ðŸ§ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "JS_Vhjg2LieN",
      "metadata": {
        "id": "JS_Vhjg2LieN"
      },
      "outputs": [],
      "source": [
        "# Creating the embeddding function here\n",
        "\n",
        "# Also using the latest embdedding function here :)\n",
        "# embedding_fn = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-exp-03-07\")\n",
        "# Resource has been exhausted, its not free switching to a free one :(\n",
        "\n",
        "embedding_fn = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "TFJFXEryLLnE",
      "metadata": {
        "id": "TFJFXEryLLnE"
      },
      "outputs": [],
      "source": [
        "persist_directory = 'db'\n",
        "if not os.path.exists(persist_directory):\n",
        "    os.makedirs(persist_directory, exist_ok=True)\n",
        "\n",
        "# Creating the memory vector database\n",
        "vectordb = Chroma.from_documents(documents,embedding=embedding_fn,persist_directory=persist_directory)\n",
        "\n",
        "# vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding_fn)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pIPG-66CQrtv",
      "metadata": {
        "id": "pIPG-66CQrtv"
      },
      "source": [
        "### Creating the vector retreiver"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikVNEoPix67a",
        "outputId": "81d6ca60-7cb8-4dc8-aa80-9b49bc4ebfe6"
      },
      "id": "ikVNEoPix67a",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "4yLobB_VQwKP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4yLobB_VQwKP",
        "outputId": "c58c3208-741b-44e0-b44c-baeb6694cdf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2025-05-17 01:15:52.772\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 0>\u001b[0m:\u001b[36m3\u001b[0m - \u001b[34m\u001b[1mpage_content='forms, including paper, hardware, and software ones. The userâ€™s private key is used to \n",
            "sign transactions before they are broadcast to the network and validated by miners.\n",
            "Because Bitcoin is decentralised, it is not governed by a bank or other centralised \n",
            "entity. Instead, it is kept up by a group of autonomous nodes connected by a network. \n",
            "As a result, censorship and manipulation cannot affect Bitcoin.\n",
            "Cryptography is used by Bitcoin to safeguard transactions and regulate the \n",
            "issuance of new units of the currency. The system uses sophisticated mathematical \n",
            "techniques to ensure that transactions cannot be copied or faked, and transactions \n",
            "are signed with cryptographic keys that are specific to each user and are generated for \n",
            "each transaction.\n",
            "Transaction fees, which are paid to miners to entice them to process the \n",
            "transaction, may apply to bitcoin transactions. The cost is often determined by the \n",
            "transactionâ€™s size in bytes and the networkâ€™s level of congestion at the time.\n",
            "The finite supply of Bitcoin is one of its main characteristics. There will only ever be \n",
            "21 million bitcoins in circulation, and the creation rate will gradually decline over time. \n",
            "Due to this, Bitcoin is a deflationary currency, which implies that its value will likely rise \n",
            "with time.\n",
            "The anonymity of Bitcoin is a key component. Users can conduct transactions on \n",
            "the Bitcoin network without disclosing their identities since transactions on the network' metadata={'creationdate': '2023-04-27T10:54:25+05:30', 'page': 237, 'producer': 'PDFill PDF Editor 15.0', 'moddate': '2023-04-28T09:37:03+05:30', 'source': '/content/docs/Blockchain Technologies F-CSIT358-B.pdf', 'page_label': '238', 'creator': 'Adobe InDesign CS6 (Windows)', 'trapped': '/False', 'total_pages': 297}\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "retriever = vectordb.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 7})\n",
        "retrieved_docs = retriever.invoke(\"What is benefit of Bitcoin?\")\n",
        "logger.debug(retrieved_docs[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "i1YkSgYKRl93",
      "metadata": {
        "id": "i1YkSgYKRl93"
      },
      "source": [
        "### Invoking the LLM to structure and return the response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "aDFtNcu6R8eh",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDFtNcu6R8eh",
        "outputId": "d804c3d9-f825-4064-eb12-c0c61b8f0adf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2025-05-17 01:21:27.232\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 0>\u001b[0m:\u001b[36m1\u001b[0m - \u001b[1mInitializing the Gemini LLM instance\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "logger.info(\"Initializing the Gemini LLM instance\")\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\",temperature=0, max_tokens=500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "hEjXrGWUS4Zy",
      "metadata": {
        "id": "hEjXrGWUS4Zy"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "system_prompt = (\n",
        "    \"You are an assistant for question-answering tasks. \"\n",
        "    \"Use the following pieces of retrieved context to answer the question.\"\n",
        "    \"If you don't know the answer, say that you don't know.\"\n",
        "    \"Use three sentences maximum and keep the answer concise.\"\n",
        "    \"\\n\\n\"\n",
        "    \"{context}\"\n",
        "    \"Below are some examples showing a question and answer format:\"\n",
        "    \"\"\"\n",
        "    Question: The use of e-governance helps make all functions of the ____________ transparent.\n",
        "              Question 1\n",
        "              Answer a. retail.\n",
        "              b. business.\n",
        "              c. Both A & B.\n",
        "              d. None of the above.\n",
        "\n",
        "    Answer:  b. business.\n",
        "                Because e-governance is a system that uses technology to improve the efficiency and transparency of government operations, making it easier for citizens to access information and services.\n",
        "\n",
        "\n",
        "    Question: __________does not directly links to accountability.\n",
        "\n",
        "              Question 2Answer\n",
        "              a.\n",
        "              Opaque.\n",
        "              b.\n",
        "              Transparency.\n",
        "              c.\n",
        "              Both A & B.\n",
        "              d.\n",
        "              None of the above.\n",
        "\n",
        "    Answer:  a. Opaque.\n",
        "                Because Opaque means not able to be seen through; not transparent. In the context of accountability, it suggests a lack of clarity or openness in processes or decisions, which does not directly link to accountability.\n",
        "\n",
        "\n",
        "\n",
        "    Now, Answer the user question correctly given the example formats above:\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_prompt),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "vgmr5h1xTA74",
      "metadata": {
        "id": "vgmr5h1xTA74"
      },
      "outputs": [],
      "source": [
        "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
        "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "3NSN_jgiTC94",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NSN_jgiTC94",
        "outputId": "51168f47-b0e6-454a-af36-4b9a36cfbac4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: c. A person can work on different approach.\n",
            "Because data science is a multidisciplinary field that combines mathematics, statistics, artificial intelligence, and computer engineering to analyze vast volumes of data and derive useful insights for businesses. It enables the discovery of hidden patterns, the creation of prediction models, and better decision-making. Data science also helps in automating processes, constructing superior products, and evaluating opportunities.\n"
          ]
        }
      ],
      "source": [
        "response = rag_chain.invoke({\"input\": \"\"\"\n",
        "What is the advantage of Data Science?\n",
        "\n",
        "Question 1Answer\n",
        "a.\n",
        "It is blurry\n",
        "\n",
        "b.\n",
        "Gives good salary\n",
        "\n",
        "c.\n",
        "A person can work on different approach\n",
        "\n",
        "d.\n",
        "It is very good defined\n",
        "\"\"\"})\n",
        "print(response[\"answer\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b93e9b98-c290-42dd-9991-85432944135d",
      "metadata": {
        "id": "b93e9b98-c290-42dd-9991-85432944135d"
      },
      "source": [
        "## 3. Creating the UI"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66425af824fb172d",
      "metadata": {
        "id": "66425af824fb172d"
      },
      "source": [
        "### 3.1. Using Gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "\n",
        "def answer_question(question: str) -> str:\n",
        "    response = rag_chain.invoke({\"input\": question})\n",
        "    return response.get(\"answer\", \"No answer found\")\n",
        "\n",
        "\n",
        "\n",
        "app = gr.Interface(\n",
        "    fn=answer_question,\n",
        "    inputs=gr.Textbox(lines=10, label=\"Enter your question\"),\n",
        "    outputs=gr.Textbox(label=\"Answer\"),\n",
        "    title=\"RAG Question Answering\"\n",
        ")\n",
        "\n",
        "app.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "45dyZodb0Dvc",
        "outputId": "c8da8fdd-2edf-4fa4-d767-83bd91a229aa"
      },
      "id": "45dyZodb0Dvc",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://f23284466eb85b62bf.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://f23284466eb85b62bf.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "STuHUBd_0s0a"
      },
      "id": "STuHUBd_0s0a",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}